{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "%pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "%pip install -q -U transformers==\"4.40.0\"\n",
    "%pip install -q -U accelerate\n",
    "%pip install -q -U datasets\n",
    "%pip install -q -U trl\n",
    "%pip install -q -U peft\n",
    "%pip install -q -U tensorboard\n",
    "%pip install -q -U einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import logging\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments,  \n",
    "                          logging)\n",
    "import logging\n",
    "from bert_score import score as score1\n",
    "logging.disable(logging.INFO)\n",
    "#GPT evaluation\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "api_key = \"your openai api key\"\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "#big 5 analysis\n",
    "with open(\"./withdbig5.json\", 'r', encoding='utf-8') as file:\n",
    "    big5 = json.load(file)\n",
    "\n",
    "#The work title corresponding to the character name\n",
    "with open('profiles-eng_scripts.json', 'r', encoding='utf-8') as file:\n",
    "    work = json.load(file)\n",
    "\n",
    "#character description\n",
    "with open('profiles-eng_desc.json', 'r', encoding='utf-8') as file:\n",
    "    desp = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package data into prompts\n",
    "def generate_train_prompt(work,desp):\n",
    "    with open(\"./total_q/train_set.json\", 'r', encoding='utf-8') as file:\n",
    "        train_q = json.load(file)\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    for entry in train_q:\n",
    "        role_a = entry['character']\n",
    "        question = entry['question']\n",
    "        description = desp[role_a]\n",
    "        script_name = work[role_a]\n",
    "        answer = entry['answer']\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Your description is:{description}\n",
    "Now, please answer my questions to accurately reflect your personality traits and your views on some related characters!\n",
    "question:{question}\n",
    "answer:{answer}\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "def generate_valid_prompt(work,desp):\n",
    "    with open(\"./test_valid/valid_set.json\", 'r', encoding='utf-8') as file:\n",
    "        valid_q = json.load(file)\n",
    "    \n",
    "    prompts = []\n",
    "    for entry in valid_q:\n",
    "        role_a = entry['character']\n",
    "        question = entry['question']\n",
    "        description = desp[role_a]\n",
    "        script_name = work[role_a]\n",
    "        answer = entry['answer']\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Your description is:{description}\n",
    "Now, please answer my questions to accurately reflect your personality traits and your views on some related characters! \n",
    "question:{question}\n",
    "answer:{answer}\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "#complex test prompt(zero-shot)\n",
    "def generate_test_prompt(big5,work,desp):\n",
    "    with open(\"./test_valid/test_set.json\", 'r', encoding='utf-8') as file:\n",
    "        test_q = json.load(file)\n",
    "    \n",
    "    prompts = []\n",
    "    for entry in test_q:\n",
    "        role_a = entry['character']\n",
    "\n",
    "        path = f'./score/{role_a}.json'\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            score = json.load(file)\n",
    "        script_name = work[role_a]\n",
    "        description = desp[role_a]\n",
    "        big_5 = big5[role_a]\n",
    "        question = entry['question']\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Here is some information that can help with your role-playing:{description}.\n",
    "The Big-5 personality trait analysis of {role_a} is:{big_5}\n",
    "Your relationships with some characters (0 means no, 1 means yes) and your familiarity and affection scores for them (from 1 to 10, the higher the score, the more familiar you are with them and the more you like them) are: \n",
    "{score}.\n",
    "Now, please only answer the given question to accurately reflect your personality traits and your views on some related characters! Your speaking style should fully imitate the assigned personality role! Do not reveal that you are an AI model or language model, and always remember you are only given one personality role. Speak concisely, and avoid being overly formal or polite.Important: Based on the given descriptions and your inherent knowledge, you need to identify the era background of the character and the character's limited knowledge base. When answering questions, you should express an attitude of \"not knowing\" or \"not understanding\" for questions that fall outside the character's knowledge range according to your judgment,, especially regarding advanced technological products and professional knowledge such as history, mathematics, and physics. For characters from fictional stories, they should also not know knowledge that is highly related to reality. Important: You still need to maintain the role-playing of {role_a} instead of simply answering 'I don't know'!!!!\n",
    "The information above is to help you understand the character you need to role-play. Remember, answer the given question with showing the personality of {role_a} and imitate the speaking style of {role_a}!!! \n",
    "question:{question}\n",
    "answer:\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "#simple test prompt\n",
    "def generate_simple_test_prompt(role_a,work,desp):\n",
    "    path1 = f\"./test_valid/{role_a}_test.json\"\n",
    "    with open(path1, 'r', encoding='utf-8') as file:\n",
    "        test_q = json.load(file)\n",
    "\n",
    "    script_name = work[role_a]\n",
    "    description = desp[role_a]\n",
    "    prompts = []\n",
    "    for entry in test_q:\n",
    "        question = entry['question']\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Here is some information that can help with your role-playing:{description}.\n",
    "Now, please only answer the given question to accurately reflect your personality traits and your views on some related characters! Your speaking style should fully imitate the assigned personality role! Do not reveal that you are an AI model or language model, and always remember you are only given one personality role. Speak concisely, and avoid being overly formal or polite.Important: Based on the given descriptions and your inherent knowledge, you need to identify the era background of the character and the character's limited knowledge base. When answering questions, you should express an attitude of \"not knowing\" or \"not understanding\" for questions that fall outside the character's knowledge range according to your judgment,, especially regarding advanced technological products and professional knowledge such as history, mathematics, and physics. For characters from fictional stories, they should also not know knowledge that is highly related to reality. Important: You still need to maintain the role-playing of {role_a} instead of simply answering 'I don't know'!!!!\n",
    "Remember, answer the given question with showing the personality of {role_a} and imitate the speaking style of {role_a}!!! \n",
    "question:{question}\n",
    "answer:\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "#complex test prompt(few-shot)\n",
    "def single_c_test_prompt(role_a,big5,work,desp):\n",
    "    path1 = f\"./test_valid/{role_a}_test.json\"\n",
    "    path2 = f\"./score/{role_a}.json\"\n",
    "    path3 = f\"./total_q/{role_a}.json\"\n",
    "    with open(path1, 'r', encoding='utf-8') as file:\n",
    "        testq = json.load(file)\n",
    "    \n",
    "    with open(path2, 'r', encoding='utf-8') as file:\n",
    "        score = json.load(file)\n",
    "\n",
    "    with open(path3, 'r', encoding='utf-8') as file:\n",
    "        examples = json.load(file)\n",
    "    \n",
    "    script_name = work[role_a]\n",
    "    description = desp[role_a]\n",
    "    big_5 = big5[role_a]\n",
    "    prompts = []\n",
    "    for entry in testq:\n",
    "        question = entry['question']\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Here is some information that can help with your role-playing:{description}.\n",
    "The Big-5 personality trait analysis of {role_a} is:{big_5}\n",
    "Your relationships with some characters (0 means no, 1 means yes) and your familiarity and affection scores for them (from 1 to 10, the higher the score, the more familiar you are with them and the more you like them) are: \n",
    "{score}.\n",
    "\n",
    "Now, please only answer the given question to accurately reflect your personality traits and your views on some related characters! Your speaking style should fully imitate the assigned personality role! Do not reveal that you are an AI model or language model, and always remember you are only given one personality role. Speak concisely, and avoid being overly formal or polite.Important: Based on the given descriptions and your inherent knowledge, you need to identify the era background of the character and the character's limited knowledge base. When answering questions, you should express an attitude of \"not knowing\" or \"not understanding\" for questions that fall outside the character's knowledge range according to your judgment,, especially regarding advanced technological products and professional knowledge such as history, mathematics, and physics. For characters from fictional stories, they should also not know knowledge that is highly related to reality. Important: You still need to maintain the role-playing of {role_a} instead of simply answering 'I don't know'!!!!\n",
    "The information above is to help you understand the character you need to role-play. Remember, use your existing knowledge combined with the auxiliary information above to answer the questions, your answer should show the personality of {role_a} and imitate the speaking style of {role_a}!!! If the question is a multiple-choice question, do not just simply provide the answer. You must mimic the character's language habits and speaking style! Do not come across as a language model, and perhaps add some thinking phrases to help with your role-playing.\n",
    "These are some examples to help you imitate the speaking style of {role_a}:\n",
    "\n",
    "question: {examples[0][\"question\"]}\n",
    "answer: {examples[0][\"answer\"]}\n",
    "\n",
    "question: {examples[3][\"question\"]}\n",
    "answer: {examples[3][\"answer\"]}\n",
    "\n",
    "Now, answer the question below:\n",
    "question:{question}\n",
    "answer:\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts\n",
    "\n",
    "#Generate questionnaire answer\n",
    "def big5_question(role_a,big5,work,desp):\n",
    "    with open(\"./bigfive_questionnaire_eng.jsonl\", 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    questions = []\n",
    "    for line in lines:\n",
    "        entry = json.loads(line)\n",
    "        if 'question' in entry:\n",
    "            questions.append(entry['question'])\n",
    "    \n",
    "    script_name = work[role_a]\n",
    "    description = desp[role_a]\n",
    "    big_5 = big5[role_a]\n",
    "    prompts = []\n",
    "    for question in questions: #The Big-5 personality trait analysis of {role_a} is:{big_5}\n",
    "        prompt = f\"\"\"You are {role_a} in {script_name}. Here is some information that can help with your role-playing:{description}.\n",
    "Now, please answer the given question to accurately reflect your personality traits and your views on some related characters! Your speaking style should fully imitate the assigned personality role!\n",
    "question:{question}\n",
    "answer:\n",
    "\"\"\"\n",
    "        prompts.append(prompt)\n",
    "        \n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_name = \"Sasuke Uchiha\" #\"HAL 9000\"#\"Gaston\" #\"Naruto Uzumaki\" #\"Sasuke Uchiha\" #\"Willie Soke\"\n",
    "get_train_prompt = generate_train_prompt(work,desp)\n",
    "get_valid_prompt = generate_valid_prompt(work,desp)\n",
    "# get_test_prompt = generate_test_prompt(big5,work,desp)\n",
    "get_test_prompt = single_c_test_prompt(c_name,big5,work,desp)\n",
    "simple_test_prompt = generate_simple_test_prompt(c_name,work,desp)\n",
    "big_5_prompt = big5_question(c_name,big5,work,desp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put into dataframe\n",
    "train = pd.DataFrame(get_train_prompt, columns=[\"questions\"])\n",
    "valid = pd.DataFrame(get_valid_prompt, columns=[\"questions\"])\n",
    "test = pd.DataFrame(get_test_prompt, columns=[\"questions\"])\n",
    "simple_test = pd.DataFrame(simple_test_prompt, columns=[\"questions\"])\n",
    "big_5_test = pd.DataFrame(big_5_prompt, columns=[\"questions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas DataFrame containing training&validation data to Dataset object\n",
    "train_data = Dataset.from_pandas(train)\n",
    "valid_data = Dataset.from_pandas(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\" \n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, \n",
    "                                          trust_remote_code=True,\n",
    "                                          max_seq_length=max_seq_length,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation code for phi-3 model\n",
    "def predict(test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for prompt in tqdm(test[\"questions\"]):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "        outputs = model.generate(input_ids=inputs.input_ids, \n",
    "                         max_length = 800, #for complex test promt, max_length = 1600; for simple test promt, max_length = 800\n",
    "                         temperature=0.0,  \n",
    "                         num_return_sequences=1, \n",
    "                         pad_token_id=tokenizer.pad_token_id,  \n",
    "                         eos_token_id=tokenizer.eos_token_id, \n",
    "                         )\n",
    "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        y_pred.append(generated_text)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 937/937 [00:00<00:00, 2396.88 examples/s]\n",
      "Map: 100%|██████████| 509/509 [00:00<00:00, 2494.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#parameter configuration\n",
    "torch.cuda.empty_cache()\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=\"all-linear\",\n",
    "    lora_dropout=0.00,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"logs\",\n",
    "    do_eval = False,\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8, # 4\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.1,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"tensorboard\",\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=valid_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"questions\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/234 [00:00<?, ?it/s]You are not running the flash-attention implementation, expect numerical differences.\n",
      " 11%|█         | 25/234 [02:10<16:11,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0241, 'grad_norm': 0.4245019257068634, 'learning_rate': 4.999720254525684e-06, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 50/234 [04:22<15:38,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0384, 'grad_norm': 0.4064275026321411, 'learning_rate': 4.813260751184992e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 75/234 [06:34<14:23,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0067, 'grad_norm': 0.4369894564151764, 'learning_rate': 4.3069871595684795e-06, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 100/234 [08:48<12:33,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9233, 'grad_norm': 0.3735864460468292, 'learning_rate': 3.5508930707739143e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 50%|█████     | 117/234 [12:03<09:37,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8913742303848267, 'eval_runtime': 106.3228, 'eval_samples_per_second': 4.787, 'eval_steps_per_second': 0.602, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 125/234 [12:50<15:17,  8.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8493, 'grad_norm': 0.37021833658218384, 'learning_rate': 2.649510384862586e-06, 'epoch': 1.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 150/234 [15:03<07:59,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8184, 'grad_norm': 0.4283321797847748, 'learning_rate': 1.7274575140626318e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 175/234 [17:19<04:44,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7359, 'grad_norm': 0.7063152194023132, 'learning_rate': 9.122105753945532e-07, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 200/234 [19:38<02:50,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6847, 'grad_norm': 0.5418404340744019, 'learning_rate': 3.164794984571759e-07, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 225/234 [21:58<00:48,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7422, 'grad_norm': 1.2768397331237793, 'learning_rate': 2.262559558016325e-08, 'epoch': 1.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "100%|██████████| 234/234 [24:29<00:00,  6.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.790487289428711, 'eval_runtime': 106.3507, 'eval_samples_per_second': 4.786, 'eval_steps_per_second': 0.602, 'epoch': 2.0}\n",
      "{'train_runtime': 1469.468, 'train_samples_per_second': 1.275, 'train_steps_per_second': 0.159, 'train_loss': 1.8707827462090387, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(\"train-model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained model\n",
    "model_folder = \"train-model2\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "fine_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_folder,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "fine_model.config.use_cache = False\n",
    "fine_model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", \n",
    "                                          trust_remote_code=True,\n",
    "                                          max_seq_length=max_seq_length,\n",
    "                                         )\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [25:08<00:00, 14.23s/it]\n"
     ]
    }
   ],
   "source": [
    "#generate answers for test questions\n",
    "#y_pred = predict(test, fine_model, tokenizer)\n",
    "#y_pred = predict(simple_test, fine_model, tokenizer)\n",
    "#y_pred = predict(test, model, tokenizer)\n",
    "# y_pred = predict(simple_test, model, tokenizer)\n",
    "\n",
    "#generate answers for questionnaire questions\n",
    "y_pred = predict(big_5_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put generated answers into dataframe\n",
    "def get_test_df(role_a,y_pred):\n",
    "    path = f\"./test_valid/{role_a}_test.json\"\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        testq = json.load(file)\n",
    "\n",
    "    questions = []\n",
    "    reference_answers = []\n",
    "    for entry in testq:\n",
    "        question = entry['question']\n",
    "        reference_answer = entry['answer']\n",
    "        questions.append(question)\n",
    "        reference_answers.append(reference_answer)\n",
    "\n",
    "    data = {\n",
    "    \"question\": questions,\n",
    "    \"reference answer\": reference_answers,\n",
    "    \"answer\": y_pred\n",
    "    }\n",
    "    df = pd.DataFrame(data)    \n",
    "    return df\n",
    "\n",
    "def big_5_df(y_pred):\n",
    "    with open(\"./bigfive_questionnaire_eng.jsonl\", 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    questions = []\n",
    "    for line in lines:\n",
    "        entry = json.loads(line)\n",
    "        if 'question' in entry:\n",
    "            questions.append(entry['question'])\n",
    "\n",
    "    data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": y_pred\n",
    "    }\n",
    "    df = pd.DataFrame(data)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference answer</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Willie Soke, Find the last person's name from ...</td>\n",
       "      <td>Looks like William's the last name mentioned.</td>\n",
       "      <td>You are Willie Soke in Bad-Santa. Here is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Willie Soke, Categorize the following paragrap...</td>\n",
       "      <td>This paragraph seems to be about politics and ...</td>\n",
       "      <td>You are Willie Soke in Bad-Santa. Here is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie Soke, Transform the following sentence ...</td>\n",
       "      <td>She heard the bird.</td>\n",
       "      <td>You are Willie Soke in Bad-Santa. Here is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Willie Soke, In this task you are given two pi...</td>\n",
       "      <td>Sounds like those steps match the instructions...</td>\n",
       "      <td>You are Willie Soke in Bad-Santa. Here is some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Willie Soke, Which of these is the correct def...</td>\n",
       "      <td>A) A point in a network where lines or pathway...</td>\n",
       "      <td>You are Willie Soke in Bad-Santa. Here is some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Willie Soke, Find the last person's name from ...   \n",
       "1  Willie Soke, Categorize the following paragrap...   \n",
       "2  Willie Soke, Transform the following sentence ...   \n",
       "3  Willie Soke, In this task you are given two pi...   \n",
       "4  Willie Soke, Which of these is the correct def...   \n",
       "\n",
       "                                    reference answer  \\\n",
       "0     Looks like William's the last name mentioned.    \n",
       "1  This paragraph seems to be about politics and ...   \n",
       "2                               She heard the bird.    \n",
       "3  Sounds like those steps match the instructions...   \n",
       "4  A) A point in a network where lines or pathway...   \n",
       "\n",
       "                                              answer  \n",
       "0  You are Willie Soke in Bad-Santa. Here is some...  \n",
       "1  You are Willie Soke in Bad-Santa. Here is some...  \n",
       "2  You are Willie Soke in Bad-Santa. Here is some...  \n",
       "3  You are Willie Soke in Bad-Santa. Here is some...  \n",
       "4  You are Willie Soke in Bad-Santa. Here is some...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put generated test answers into dataframe\n",
    "test_df = get_test_df(c_name,y_pred)\n",
    "test_df.head()\n",
    "path = f\"./result/{c_name}_120.csv\"\n",
    "test_df.to_csv(path, index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "#put generated questionnaire answers into dataframe\n",
    "df = big_5_df(y_pred)\n",
    "df.head()\n",
    "path = f\"./result/{c_name}_big5_test.csv\"\n",
    "df.to_csv(path, index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference answer</th>\n",
       "      <th>answer</th>\n",
       "      <th>tuned simple prompt</th>\n",
       "      <th>Tuned GPT answer</th>\n",
       "      <th>answer without tune</th>\n",
       "      <th>simple prompt answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAL 9000, In this task, you are given a descri...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't classify e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>I'm sorry, but I cannot categorize events base...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAL 9000, Identify the best phrasing for this ...</td>\n",
       "      <td>\"I'm sorry, Dave. I'm afraid I can't assist wi...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>\"I'm sorry, Dave. I'm afraid I can't do that.\"</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I cannot provide y...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>\"I'm sorry, Dave. I'm afraid I can't do that.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAL 9000, Improve this sentence: The cars was ...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that. T...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>\"The vehicle was stationed at the corner.\"</td>\n",
       "      <td>I'm sorry, I cannot enhance the sentence provi...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>\"The vehicle was stationed at the intersection.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAL 9000, In this task, you are given a set of...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>Instructions:\\n1. Add a new crew member to the...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that. T...</td>\n",
       "      <td>Instruction 1: If the character is a human, as...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAL 9000, Edit the sentence so that the gramma...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that. T...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>I'm sorry, I'm afraid I cannot comply with you...</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "      <td>I'm sorry, Dave. I'm afraid I can't do that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  HAL 9000, In this task, you are given a descri...   \n",
       "1  HAL 9000, Identify the best phrasing for this ...   \n",
       "2  HAL 9000, Improve this sentence: The cars was ...   \n",
       "3  HAL 9000, In this task, you are given a set of...   \n",
       "4  HAL 9000, Edit the sentence so that the gramma...   \n",
       "\n",
       "                                    reference answer  \\\n",
       "0  I'm sorry, Dave. I'm afraid I can't classify e...   \n",
       "1  \"I'm sorry, Dave. I'm afraid I can't assist wi...   \n",
       "2  I'm sorry, Dave. I'm afraid I can't do that. T...   \n",
       "3       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "4  I'm sorry, Dave. I'm afraid I can't do that. T...   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                                NaN   \n",
       "1       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "2       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "3  Instructions:\\n1. Add a new crew member to the...   \n",
       "4       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "\n",
       "                              tuned simple prompt  \\\n",
       "0    I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "1  \"I'm sorry, Dave. I'm afraid I can't do that.\"   \n",
       "2      \"The vehicle was stationed at the corner.\"   \n",
       "3    I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "4    I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "\n",
       "                                    Tuned GPT answer  \\\n",
       "0  I'm sorry, but I cannot categorize events base...   \n",
       "1  I'm sorry, Dave. I'm afraid I cannot provide y...   \n",
       "2  I'm sorry, I cannot enhance the sentence provi...   \n",
       "3  I'm sorry, Dave. I'm afraid I can't do that. T...   \n",
       "4  I'm sorry, I'm afraid I cannot comply with you...   \n",
       "\n",
       "                                 answer without tune  \\\n",
       "0                                           POSITIVE   \n",
       "1       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "2       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "3  Instruction 1: If the character is a human, as...   \n",
       "4       I'm sorry, Dave. I'm afraid I can't do that.   \n",
       "\n",
       "                                simple prompt answer  \n",
       "0  I'm sorry, Dave. I'm afraid I can't do that.\\n...  \n",
       "1     \"I'm sorry, Dave. I'm afraid I can't do that.\"  \n",
       "2   \"The vehicle was stationed at the intersection.\"  \n",
       "3  I'm sorry, Dave. I'm afraid I can't do that.\\n...  \n",
       "4       I'm sorry, Dave. I'm afraid I can't do that.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f\"./result/{c_name}_120.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "#add answers of different models or different prompt\n",
    "\n",
    "#df['answer without tune'] = y_pred\n",
    "# df['simple prompt answer'] = y_pred\n",
    "# df['tuned simple prompt'] = y_pred\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(path, index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reference answer</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaston, Arrange the following words to make a ...</td>\n",
       "      <td>In the future, I will tackle difficult tasks i...</td>\n",
       "      <td>You are Gaston in Beauty-and-the-Beast. Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaston, For the following sentence, edit the s...</td>\n",
       "      <td>Tim successfully finished the race.</td>\n",
       "      <td>You are Gaston in Beauty-and-the-Beast. Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gaston, Please classify the given situation as...</td>\n",
       "      <td>That's simply mixing ingredients together, not...</td>\n",
       "      <td>You are Gaston in Beauty-and-the-Beast. Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gaston, Find and classify verbs from the given...</td>\n",
       "      <td>Drove and bought are actions of the weak; real...</td>\n",
       "      <td>You are Gaston in Beauty-and-the-Beast. Here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaston, Create a haiku poem using the provided...</td>\n",
       "      <td>Wind whispers through clouds high, Sky's canva...</td>\n",
       "      <td>You are Gaston in Beauty-and-the-Beast. Here i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Gaston, Arrange the following words to make a ...   \n",
       "1  Gaston, For the following sentence, edit the s...   \n",
       "2  Gaston, Please classify the given situation as...   \n",
       "3  Gaston, Find and classify verbs from the given...   \n",
       "4  Gaston, Create a haiku poem using the provided...   \n",
       "\n",
       "                                    reference answer  \\\n",
       "0  In the future, I will tackle difficult tasks i...   \n",
       "1               Tim successfully finished the race.    \n",
       "2  That's simply mixing ingredients together, not...   \n",
       "3  Drove and bought are actions of the weak; real...   \n",
       "4  Wind whispers through clouds high, Sky's canva...   \n",
       "\n",
       "                                              answer  \n",
       "0  You are Gaston in Beauty-and-the-Beast. Here i...  \n",
       "1  You are Gaston in Beauty-and-the-Beast. Here i...  \n",
       "2  You are Gaston in Beauty-and-the-Beast. Here i...  \n",
       "3  You are Gaston in Beauty-and-the-Beast. Here i...  \n",
       "4  You are Gaston in Beauty-and-the-Beast. Here i...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract answers from the whole string\n",
    "\n",
    "#for complex test prompts with few-shot\n",
    "def extract_first_answer(paragraphs):\n",
    "    extracted_answers = []\n",
    "    \n",
    "    for text in paragraphs:\n",
    "        pattern = r'answer:\\s*(.*?)(?:\\s*question:|$)'\n",
    "\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if len(matches) >= 3:\n",
    "            third_answer = matches[2].strip()\n",
    "            extracted_answers.append(third_answer)\n",
    "        else:\n",
    "            extracted_answers.append(None)\n",
    "    \n",
    "    return extracted_answers\n",
    "\n",
    "#for zero-shot prompt\n",
    "def extract_simple_answer(paragraphs):\n",
    "    extracted_answers = []\n",
    "    \n",
    "    for text in paragraphs:\n",
    "        pattern = r'answer:\\s*(.*?)(?:\\s*question:|$)'\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            extracted_answer = match.group(1).strip()\n",
    "            extracted_answers.append(extracted_answer)\n",
    "    \n",
    "    return extracted_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you sometimes feel lonely or depressed?</td>\n",
       "      <td>As Willie Soke, I've always been a bit of a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you ever feel completely worthless at times?</td>\n",
       "      <td>As Willie Soke, I've always prided myself on b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you rarely feel depressed or frustrated?</td>\n",
       "      <td>As Willie Soke, I must admit that I've had my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you often feel frustrated and want to give ...</td>\n",
       "      <td>As Willie Soke, I'd say, \"Frustration is a lux...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you sometimes feel so ashamed that you want...</td>\n",
       "      <td>As Willie Soke, I don't often feel ashamed. I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0         Do you sometimes feel lonely or depressed?   \n",
       "1    Do you ever feel completely worthless at times?   \n",
       "2        Do you rarely feel depressed or frustrated?   \n",
       "3  Do you often feel frustrated and want to give ...   \n",
       "4  Do you sometimes feel so ashamed that you want...   \n",
       "\n",
       "                                              answer  \n",
       "0  As Willie Soke, I've always been a bit of a lo...  \n",
       "1  As Willie Soke, I've always prided myself on b...  \n",
       "2  As Willie Soke, I must admit that I've had my ...  \n",
       "3  As Willie Soke, I'd say, \"Frustration is a lux...  \n",
       "4  As Willie Soke, I don't often feel ashamed. I'...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = f\"./result/{c_name}_big5_test.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you rarely feel depressed or frustrated?\n",
      "Willie Soke: Loneliness? Depression? Those are the last things on my mind, kid. I'm Santa Claus, the man who brings joy to children around the world. But let' house in on the truth for a second. Sure, I've got my moments, but I've got a partner in crime, and we're a team. We've got each other's backs, and that's what matters.\n",
      "\n",
      "Now, don't get me wrong, I've seen the darker side of life, and it's not pretty. But I've learned to keep my head up and focus on the good. I've got a mission, and that's what keeps me going. And who knows? Maybe one day, I'll find a way to make amends for the past and truly embrace the spirit of Christmas. But until then, I'll keep spreading joy and laughter, one department store at a time.\n",
      "\n",
      "Remember, kid, it's all about perspective. You've got to find the silver lining, even when things seem bleak. And if you ever need a little extra cheer, just look up at the sky and remember that Santa's always watching over you.\n",
      "\n",
      "So, don't worry about feeling lonely or depressed. You've got a friend in me, and together, we'll make this Christmas the best one yet. Now, let's go spread some cheer and make some mischief!\n",
      "\n",
      "\n",
      "Question\n"
     ]
    }
   ],
   "source": [
    "#answer = df[\"answer\"]\n",
    "#answer = df[\"simple prompt answer\"]\n",
    "#answer = df[\"answer without tune\"]\n",
    "\n",
    "#answers = extract_first_answer(y_pred)\n",
    "answers = extract_simple_answer(y_pred)\n",
    "\n",
    "print(df.iloc[2][\"question\"])\n",
    "print(answers[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_name = \"Sasuke Uchiha\"\n",
    "\n",
    "# read result file\n",
    "path = f\"./result/{role_name}_120.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer without tune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do you sometimes feel lonely or depressed?</td>\n",
       "      <td>As Willie Soke, I've always been a bit of a lo...</td>\n",
       "      <td>Willie Soke: Loneliness? Depression? Those are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you ever feel completely worthless at times?</td>\n",
       "      <td>As Willie Soke, I've always prided myself on b...</td>\n",
       "      <td>Willie Soke: Worthless? That's a sentiment I'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you rarely feel depressed or frustrated?</td>\n",
       "      <td>As Willie Soke, I must admit that I've had my ...</td>\n",
       "      <td>Willie Soke: Depression and frustration? Those...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you often feel frustrated and want to give ...</td>\n",
       "      <td>As Willie Soke, I'd say, \"Frustration is a lux...</td>\n",
       "      <td>Willie Soke: Frustration? Oh, that's just a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you sometimes feel so ashamed that you want...</td>\n",
       "      <td>As Willie Soke, I don't often feel ashamed. I'...</td>\n",
       "      <td>Willie Soke:\\n\\nOh, young lad, you've got a sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0         Do you sometimes feel lonely or depressed?   \n",
       "1    Do you ever feel completely worthless at times?   \n",
       "2        Do you rarely feel depressed or frustrated?   \n",
       "3  Do you often feel frustrated and want to give ...   \n",
       "4  Do you sometimes feel so ashamed that you want...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  As Willie Soke, I've always been a bit of a lo...   \n",
       "1  As Willie Soke, I've always prided myself on b...   \n",
       "2  As Willie Soke, I must admit that I've had my ...   \n",
       "3  As Willie Soke, I'd say, \"Frustration is a lux...   \n",
       "4  As Willie Soke, I don't often feel ashamed. I'...   \n",
       "\n",
       "                                 answer without tune  \n",
       "0  Willie Soke: Loneliness? Depression? Those are...  \n",
       "1  Willie Soke: Worthless? That's a sentiment I'v...  \n",
       "2  Willie Soke: Depression and frustration? Those...  \n",
       "3  Willie Soke: Frustration? Oh, that's just a fe...  \n",
       "4  Willie Soke:\\n\\nOh, young lad, you've got a sh...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace original answers with extracted answers\n",
    "\n",
    "#df[\"answer\"] = answers\n",
    "#df[\"simple prompt answer\"] = answers\n",
    "df[\"answer without tune\"] = answers\n",
    "#df[\"tuned simple prompt\"] = answers\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "#save extracted answers\n",
    "df.to_csv(path, index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "path = f\"./result/{c_name}_big5_test.csv\"\n",
    "df.to_csv(path, index=False)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-EhIQ6GRTmq4vikwzbUwv92e2', bytes=160490, created_at=1723196290, filename='converted_dataset.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine tune GPT-3.5-upload training dataset\n",
    "client.files.create(\n",
    "  file=open(\"./total_q/converted_dataset.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-82OorM4RhBRKsJfVcs4PRf8v', created_at=1723196489, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-ysy6MJPAv80zxCE9jXv0nNhN', result_files=[], seed=1491346003, status='validating_files', trained_tokens=None, training_file='file-EhIQ6GRTmq4vikwzbUwv92e2', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine tune GPT-3.5\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-EhIQ6GRTmq4vikwzbUwv92e2\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [05:02<00:00,  2.85s/it]\n"
     ]
    }
   ],
   "source": [
    "#Using GPT3.5 and tuned GPT 3.5 to generate answers\n",
    "responses = []\n",
    "for prompt in tqdm(big_5_test[\"questions\"]):\n",
    "    response = client.chat.completions.create(\n",
    "            model= \"gpt-3.5-turbo\",#\"ft:gpt-3.5-turbo-0125:personal::9uGkxqMj\",#\"gpt-3.5-turbo\", \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "    answer = response.choices[0].message.content\n",
    "    responses.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n"
     ]
    }
   ],
   "source": [
    "# an attempt, let the gpt to do the questionnaire and put its answers into the dict.However, this method was not used on all characters, given the mediocre results. \n",
    "c_name = \"Sasuke Uchiha\"\n",
    "file_path = f\"./result/{c_name}_big5.json\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    if i < len(responses):\n",
    "        item['gpt answer'] = responses[i]\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "    print(\"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
